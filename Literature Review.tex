\chapter{Literature Review}
\label{chapter:Literature Review}

\section{Introduction}

In this chapter, I present a literature review of the various topics related to feedback systems, automated testing tools, mutation testing tools, and other technologies. I aim to identify potential gaps that exist in the application and implementation of feedback systems for early learners of object-oriented programming with basic knowledge of JUnit Testing. Additionally, I will also explore how mutation testing can be used to generate automated feedback hints. \\

The first paper focuses on a Feedback System that uses metrics and mutation testing to assess and enhance the code's quality. This paper also provides an overview of different types of automated feedback systems such as static analysis, dynamic analysis, requirements-based test generation, rule-based test generation, and formal methods. The paper further outlines the importance of personalized feedback in helping students become more self-directed learners and understand programming concepts better. \par

The second paper explores the use of metrics and mutation testing in order to measure code quality. It explains that while traditional approaches are good at measuring code complexity or structural coverage, they are not ideal for assessing code quality as they do not measure the correctness or robustness of a program accurately. The paper further introduces mutation testing as an effective way to evaluate code quality by introducing faults or errors into a program and then determining if these errors are detected by a set of test cases. \par

The third paper compares different mutation tools and techniques that can be used for automated software testing. It discusses how mutation testing can detect bugs that traditional approaches miss due to their focus on code coverage rather than correctness or robustness. Additionally, it provides an overview of different types of mutants such as statement deletion mutants, value assignment mutants, conditionals deletion mutants, etc., as well as techniques for generating these mutants such as classic mutation operators or genetic algorithms. \par

The fourth paper focuses on the various difficulties software testers encounter when using mutation testing tools such as false positives or difficulty in setting up the environment correctly so that all mutants can be generated accurately. It further provides some tips on how to reduce these issues such as using multiple source files or using random selection when selecting which mutants should be tested first.  \par

The fifth paper looks at the impact enhanced mutation has on software testing performance by comparing it to traditional methods such as statement coverage or branch coverage metrics. It finds that enhanced mutation is more accurate at finding errors in programs than traditional methods since it considers both structural information about a program and its data flow behavior while traditional methods mainly focus on structural information alone. Additionally, it also finds that enhanced mutation is more efficient than traditional methods since it requires fewer test cases in order to achieve similar results thus reducing the overall cost associated with the software testing process.  \par

The sixth paper focuses on researching students’ attitudes toward quality assurance practices such as writing unit tests as part of their programming projects even though they may not receive any points for doing so from their instructors or mentors. The study found that students who were given an incentive for writing unit tests were more likely to write higher quality tests than those who were not incentivized; however, this difference was small compared to those who received no monetary reward at all but still wrote higher quality tests due to having higher motivation levels stemming from their own intrinsic motivation rather than external rewards.  \par

The seventh paper explores how feedback systems can be improved by utilizing mutation testing tools in order to generate automated hints for students when they make mistakes while coding. By providing personalized hints based on each student’s individual mistakes made during coding sessions, instructors and mentors can help them correct errors faster thereby improving overall learning outcomes significantly. Furthermore, by providing customized feedback hints, students become more self-directed learners which encourage them to take more responsibility for their own learning process. \par  

The eighth paper looks at how feedback impacts students studying programming courses. The research found that providing timely feedback lead to improved programming skills even if no incentives were offered; however when incentives were offered then there was a significant improvement in student performance compared with those who received no incentives at all. Furthermore, when asked about receiving timely feedback most students felt satisfied with their experience regardless of what incentives were provided with some even recommending that teachers provide more detailed comments about their work so that they could better understand where they made mistakes. \par



\section{Customized Feedback System}
The literature review is a chapter that will assess previous and existing research studies related to feedback systems, the application of the PiTest tool, mutation testing tools, etc. Many developers have come up with feedback systems to help lecturers provide automated feedback to their students. The development of automated feedback systems that are dependable, stable, and give meaningful feedback to beginner students can be a challenging task; however, increased research on trending technology has enabled developers to overcome this challenge. Providing customized feedback can help students improve their coding skills and understand programming concepts better \cite{ref12}. Sharing and exchange of research knowledge have become crucial as new researchers keep emerging with new knowledge. By providing feedback that is customized to each student's code, instructors and mentors can provide guidance that is more detailed to students, helping them to identify areas where they need to improve and correct any mistakes they may have made. Furthermore, by giving students customized feedback, we can help them become more self-directed learners, thereby encouraging them to take more responsibility for their own learning process.\par 
Fraser and Zeller made several assessments while exploring tools used for generating test cases from mutations and unit tests from mutants \cite{ref13}. These tools such as the PiTest allow programmers to generate mutants more efficiently and in a faster way \cite{ref14}. PiTest can be quite useful in the testing process because it is very efficient and fast compared to other tools because it operates on bytecode and optimizes mutant executions in comparison with other tools. \cite{ref15}. This can help save time as well as improve the feedback by simplifying it in a more easy way to understand for students especially early learners with basic knowledge of JUnit Testing. \par 
Researchers have also explored how mutation testing can be used to generate automated feedback that is customized to each student's code \cite{ref16}. This type of mutational analysis-based feedback system has been found to provide greater insight into a student's code than traditional approaches such as static analysis or manual inspection. By utilizing mutation testing, instructors can quickly analyse a student's code and pinpoint key issues and errors made while writing JUnit Test. Mutation testing has proved an important process that has been used in this thesis to test the quality of the source codes. \par 
This literature review will identify potential gaps that exist in the application and implementation of customized feedback systems for beginner students that have basic knowledge of JUnit Testing. More so, the literature review will also explore and try to draw similarities that exist between mutation testing and traditional approaches such as static analysis or manual inspection.
\section{Study on Feedback System and Code Quality}
To study feedback systems and code quality, the concept of mutation analysis is considered \cite{ref17}. It is cost-inefficient to use lesser mutation operators because they make a downside at the reliability factor. Therefore, to overcome these challenges, the incremental subsets of deletion operators are utilized which is possible at a lower price and higher reliability.\par 
Many programs are developed in different Java languages and frequently involve numerous hardware gadgets and software modules. In order to deal with such complications while making maintenance responsibilities easy, inventors document programs with code comments and design documents. Code comments that are well-written aid developer understanding, problem-finding, and maintenance. On the other hand, the syntax of code comments is not enforced by the grammar of a programming language or examined by its compiler and is written in phrases of the English language.\par 
Static analysis tools and linters offer only minimal syntactic support for verifying the validity of comments. Thus, developers are primarily responsible for producing comments of high-quality and making sure they are up in projects. Researchers have paid a considerable amount of attention over the past decade to the issue of rating the quality of the comments in code. Researchers have a stake in this area, but they cannot seem to settle on a single definition of quality when discussing comments in code \cite{ref18}. It is not easy to provide a blanket definition of quality when discussing code comments due to the wide variety of contexts in which they may be used.\par 
Reviewing one another's work is a useful engineering practice since it guarantees high-quality, maintainable code, and facilitates knowledge sharing within a team. However, the worth and advantages teams gain through code review depend on the quality and utility of the comments they receive. Coding reviews involve multiple programmers looking at a programmer's most recent changes and discussing any issues they may have found \cite{ref19}. Finding bugs and ensuring the code is of high quality are the primary objectives of a code review. Keeping those two aims in mind is essential, even though code reviews give a far larger set of benefits, such as information distribution, learning, and mentorship. \par 
The biggest problem with code reviews is that they slow down development time for some teams. So, the team's output suffers from the time spent performing code reviews. Unit testing has been a standard practice for quite some time, and as teams expand their capabilities, the size of their test suites grows \cite{ref20}. Executing tests that span several components or involve integration takes more time. Since all code needs tests, and more of them, these suites will expand even further with the advent of unit testing techniques like TDD. A high number of unit tests can be a solid testing foundation. Still, they can significantly increase test execution time, especially if those tests are later extended to cover integration or components \cite{ref21}. Knowing the precise effect of each code change, the tests that must be executed, and the potential requirement for brand-new tests is crucial for deciding what to test.\par 
Finding problems earlier in the software development lifecycle is preferable and less expensive than finding them later when they might cause significant delays in the project's timeline. Many times, developers do not run enough or any tests because they are unsure which ones to run. \par 
As the build is configured to execute the whole suite of tests, the development team must wait for feedback/validation from the build process before proceeding with their work. Instead, development teams can use test impact analysis to determine which tests must be executed before code is committed into a build to validate the changes. The CI process can provide faster feedback to developers when code changes result in failed tests thanks to test impact analysis. It is the ideal scenario for development managers to make sure their teams perform tests before the code is checked in, but in reality, this rarely occurs. Furthermore, they want to ensure that their teams are informed as soon as possible once the code is checked in as to whether or not it caused any test failures. As a result, test effect analysis must extend to the CI process and the developer's workstation.\par 

\section{Comparative Study of Mutation Tools and Techniques}
A paper by \cite{ref22} has a detailed study of the JUnit in several mutation testing programs. This paper evaluated multiple mutation testing challenges that occurred to the software testers. The foremost challenge considered in this paper was the rising computational expenditure while executing the mutation testing. Although there are various other advantages of mutation testing, which are unfortunately overpowered by the disadvantage of computational expense. \par 
This paper further introduces approaches reduce the cost while performing mutation testing process by incorporating multiple tools such as automating the process in Java. After reviewing multiple papers related to mutation testing, the authors were able to interpret a word cloud and word frequency plot using the R-programming language by implementing these features into their analysis. It was observed that the software testers frequently utilized the mutation and test. To consider the most effective testing software, one can be evaluated using the mutation score which interprets the outcome of the mutation testing.\par 
In addition to these, the authors also studied the two approaches to generate the mutants which are the source code and byte code. With the JUnit, various other mutation testing programs for Java were also evaluated. The known mutation testing programs are MuJava, Jester, Javalanche, Jumble, PITEST, and Judy. Each of these programs has its own merits and demerits. To compare the program’s in-detail process, the paper here suggested a set of algorithms that could show the effectiveness of the program. The authors here precisely described the merits and demerits of programs in each test case. In the bottom line, it was concluded that PITEST, Jumble, and Javalanche were the most effective mutation testing programs with automation. Furthermore, the authors also stated the future scope of work, which aimed to integrate the cloud framework.\par 
Since mutation testing is a complicated process, it is necessary to automate this process to simplify it by utilizing a convenient and easy-to-use software solution that facilitates the process \cite{ref23}. The proposed approach aims to overcome these challenges. For this approach, the paper has incorporated the point cut and advice mechanism which is based on oriented programming. This mechanism accelerates the process and avoids complications. \par 
The paper also studied and described various other studies. The authors also contrasted other Java mutation testing tools such as Response Injection (RI), Judy, Jumble, MuJava, and Jumble. In the comparison, it was noted that Judy has a unique and distinct characteristic from the other mutation testing tools. It was also observed that MuJava has certain barriers which hinder the smooth process of mutant generation and compilation phases.\par 
The novel method overcomes various programming fallacies such as crosscutting concerns. Generally, in mutation testing, the compilation phase is the most time-consuming stage. Therefore, with the implementation of the Fast Aspect-Oriented Mutation Testing Algorithm (FAMTA) light, the compilation phase can be enhanced although this method brings some alterations to the mutant generation process.\\

During the generation process, the group of mutants is considered rather than the single mutants. This group of mutants is managed by meta-mutant which are responsible during every FAMTA light testing phase. This paper also described various mutation operators supported by Judy. Although, during the implementation stage, the authors stated various issues occurred. Due to the exorbitant memory size, the program caused fallacies such as performance and reliability challenges. In the conclusion, it was observed that FAMTA light could eliminate the multiple iterations which ultimately enhanced the generation and compilation stages.\par 
In \cite{ref24} a comparative study on mutation testing techniques was done. The techniques for which the software testers look are cost efficiency and feasibility. The mutation testing technique is among the most complex to use, yet it is also one of the most reliable. Therefore, in this paper, the authors compared and evaluated the different mutation techniques. Random sampling method-level, class-level, and all operators are the commonly used mutation techniques.\par 
About five Java applications are created and assessed to test each strategy. Initially, a certain algorithm is considered which is then followed for all the test case techniques. In MuJava, class-level operators are further broken down into inheritance, encapsulation, java-specific features, and polymorphism. The syntax prescribed for this operator is inserting, deleting, and modifying the expressions. Then the method-level operator which is a conventional operator in MuJava based on procedural language features follows. Like class-level operators, it also has some syntax prescribed such as inserting, replacing, and deleting.\par 
The operators are further divided into assignment operators, shift operators, conditional operators, arithmetic operators, logical operators, and relational operators. The article used these methods in addition to the automated mutation tool to improve the outcome. Five Java applications named coffee-maker, black-jack, cruise control, elevator, and find were implemented on each of the four operators. In the final experiments, the conclusion should be that all operators sampling the most effective operator. This method could effectively eliminate the mutants and provide a corroborative output of the test case. It was observed that the effectiveness of the operator is proportional to the detection of the mutants. For the future scope of work, the author aims to study in-depth relations of applications in terms of operators and applications. \par 
The sequential trend of each development phase is described and presented in \cite{ref25}. Then the theory of mutation testing is discussed. The coupling effect and the competent programmer hypothesis are the key essential hypotheses. The process and problems of each hypothesis were also discussed. Much of the cost that is spent on computing makes mutation testing expensive. The mutation-reducing strategies, including mutant sampling, weak mutation, parallel, mutant clustering, SIMD, selective mutation, high order mutation, firm mutation, compiler, mutant schemata, MIMD, and interpreter, should be taken into consideration in order to minimize costs.\par 
In \cite{ref26}, the author also discussed the development phase of each technique. On the other hand, comes the execution cost reduction technique, which is a strong, weak, firm mutation, runtime optimization technique consisting of interpreter-based and compiler-based. Numerous programming languages, including Java, Fortran, C, AOP, C, web services, security policies, SQL, network protocols, FSM, and state charts, have been subjected to mutation testing. Various other techniques and tools were also discussed with the implementations and applications. In addition to these, the historical implementations, usage, and studies related to this were also discussed. \\

There were some unresolved issues, obstacles, and expanses of success with the study. Equivalent mutants have been one of the unresolved problems in the studies. In addition to this, mutation testing is a highly expensive method which is a great barrier to implementation although it was seen that there were many points of convenience due to the larger implementation of applications and the effectiveness of the modal. The author states that for the future scope of work, there shall be increased in-depth research and study on the semantic effect.
\section{Mutation Testing Process}
The concept of test-driven development had been popular in the development phase of the software although the idea of mutation testing has been seen to be more successful than the former. To explore the hybrid model using both test-driven development (TDD) and mutation testing, the author of this research recommended. This study being novel was first introduced in this paper. The novel technique was named as TDD-M approach. The primary motive of this study was to obtain a comparison result between single and hybrid techniques \cite{ref27}. The author of the paper also discussed multiple research papers. According to the TDD approach, the developer first creates the test case before writing the model code. Although the developer must create a sizable test case, the benefit of this situation is that certain minor codes loop.\par 
Unlike TDD, mutation testing is implemented after writing the code. Certain parts of the codes are iterated with minor alterations for the mutants. The mutation score in this case determines the code's result. The white-box or fault-based testing technique was another term for the principle of mutation testing. Instead of evaluating the test cases, the author of this work analyzed the hybrid model using agile programming techniques.\par 
Confronting confirmation biases is more likely when the TDD technique is used, and as a result, it may be quickly removed. With the hybrid model of TDD-M, the bias could be effectively reduced when evaluating the test case directly. During the experimentation of TDD-M, TDD, and the Mutation test, the most effective and reliable approach was the hybrid model, TDD-M. Although during the implementation, some fallacies could be eliminated with further studies. \par 
Furthermore, the number of open-source applications containing test cases was investigated. Moreover, the applications' use of various frameworks was taken into account. To sort the project with the word, the paper here considered six different datasets with the results for the further process. Upon these different parameters were implemented such as file filtering and search method which were implemented in either java and Katlin files or project files. Once the programs were sorted, each of these programs was deeply examined to understand the reason behind the occurrences. The module of random selection implemented the process of deep examination. The article here then investigated the relationship between the word's frequency and the project properties using scatter plots. Each program's settings were put into practice using the Pearson coefficient relation.\\

Further detailed graphical representation of the number of occurrences is provided in the research paper. In the bottom line, it was observed that about 51.57\% of all projects consisted of test cases. In addition to this, it was also observed that the utilization of certain tools to predict the relevance of the project was not that productive. In the analysis of the usage of framework, the most used framework denoted is JUnit4/JUnit5, Mockito, spring framework, ham crest, etc although, there was a certain threat to the validity. For the future scope of work, the author aimed to study the example test and its automation for detection. In addition to this, the author aimed to enhance the tool by making it more time-efficient and convenient.\par 
Similarly, \cite{ref28} analyzed the metric suites for the JUnit test code. The primary aim was to propose a unified metric suite. The testing effort's development phase was interpreted and documented. Five-unit test cases were used in the study by the author. They include TNOO, TINVOK, TDATA, TLOC, and TASSERT.\par 
Six different open-source java programs, which are ANT, JFREECHART, JODA-Time, Apache Lucene Code, POI, and IVY were considered to proceed further. Considering different parameters, these programs were chosen. After the detailed interpretation of each parameter, it was observed that POI was the largest program in terms of classes whereas the smallest program in terms of classes is the JODA. Although in terms of the line of codes, the JFC is the largest. In addition to this, it is also observed that the JFC program is the most covered for the JUnit classes.\par 
To understand the proposed metric suites, the module of Principal Component Analysis (PCA) was implemented. This module also analyses the internal dimensions of the program. There is a link in between the metrics for unit test cases and the internal software class characteristic. Additionally, the study used XLSTAT to carry out the analysis in order to put this into practice. Although it poses an internal threat, it is possible to identify the connections between Java classes. On the other hand, the external threat of validity showed that the JUnit test is only developed for certain classes. In the final evaluation, the author successfully identified the test case metrics. It was also observed that TLOC and TINVOK had enhanced the obtained pieces of information. With the addition of CodePro, the author hopes to generate JUnit test cases automatically for the future scope of work.\par 
Nguyen, Quang, and Madeyski \cite{ref29} conducted a thorough analysis of the various strategies for software test case prioritization which include Test Suite Minimization and Regression Test Selection. This model generally implements the historical applications, which are also cost-time-aware, and requirement risk-aware. The paper aimed to resolve certain research questions as well. Here, the metrics utilized for the test case prioritization and synonymously studied topic were analyzed. The coverage awareness technique's objectives were to increase the test case's comprehensive coverage of all test case elements and to reveal more about the programming language.\par 
Historical awareness processes the statistical data. In this process, cost reduction and control are the primary motives, which is why the cost-cognizant approach comes into place. During the implementation phase, the time of the implementation is also a concern that is overcome by the time-aware approach. The requirement and risk-oriented approach adhere to the least available requirement and improved effort. With the growing requirements and demands, the source code must be altered periodically. This can cause inefficiency and can also introduce various bugs. To overcome this, the model-based approach is implemented whereas the approach for GUI/Web applications emphasizes the current time requirements. \par 
Apart from these, there are also various other approaches for real-world applications. In the final evaluations, it was observed that nowadays the Test-Driven Development (TDD) had been gaining momentum. Through this, the efficacy of the program had been increasing thereby reducing the overall expenditure. The author provided a certain conclusion with the sets of future scope of work.\par 
A powerful method for evaluating the efficacy of test suites is mutation testing. To determine how many mutations are eliminated, mutants are created and tested alongside the test suite. Mutation testing is therefore generally acknowledged a computationally costly method. Mutation testing commonly referred to as "program mutation," has been extensively studied over the past 40 years but rarely used as a testing criterion.\par 
Mutation operators in code produce variants of a program called mutants that can be used to mimic bugs or lead testers to edge situations \cite{ref30}. Testers must find or develop tests that cause these mutations to act differently from the original, un-mutated software in order for them to pass. If a test case fails it is said to have killed but if it passes it is said to have survived. Testers to evaluate and improve test sets that currently exist or to assist in the creation of high-quality tests can use mutation.\par 
Experimental evidence has shown that mutation testing more preferred than data-flow-based testing or control-flow-based. It has also been used to evaluate other test needs, such as test reliability. Despite its success, it is costly and challenging to utilize in practice due to various issues, including the need for several tests, the number of comparable mutations, and the vast sets of mutants that must be conducted, sometimes repeatedly. There could be hundreds of variants generated with just a few dozen lines of code in a straightforward routine. \par 
In contrast, certain mutations present greater difficulties and require extensive research on the part of the tester. Some mutants can be readily and quickly eliminated without any effort (slain by numerous tests). It is not surprising that the hardest-to-kill mutants often make the best test subjects. Nevertheless, it is hard to know if a mutant is similar or just hard to kill (and, in fact, undecidable in general). These costs have made mutation testing impractical for most people. For instance, one possible explanation for the relative rarity of mutation in practice is that it is difficult to locate individuals with the desired mutation. Researchers have responded by developing several cost-cutting solutions with varying priorities. The number of mutants must be decreased, specific mutants must not be produced, mutant execution must be sped up, test set generation must be automated, test sets must be minimized or prioritized, and automatically equivalent mutants must be identified.\par 
Many methods to lower the price of mutation testing have been put forth, created, and researched in the past. According to empirical data, mutation testing is applied to gauge test reliability and other test requirements \cite{ref31}. Despite its success, it is costly and challenging to utilize in practice due to various issues, including the requirement for several tests, the number of comparable mutations, and the vast sets of mutants that must be conducted, sometimes repeatedly. There could be hundreds of variants generated with just a few dozen lines of code in a straightforward routine. Some mutants, however, present greater difficulties and require extensive research on the part of the tester. Some mutants can be readily and quickly eliminated without any effort (slain by numerous tests).\par 
It is impossible to distinguish if a mutant is tough or hard to kill. Naturally, hard-to-kill mutants frequently serve as beneficial test subjects. The application of mutation testing in practice has been severely limited by these costs. For instance, some contend that the difficulty in locating mutants that are similar to one another is the reason mutation is commonly used \cite{ref32}. In response, researchers have developed a number of other ways to save money. The reduction of the overall mutant population, the prevention of the generation of particular mutants, the acceleration of the execution of mutants, the automatic formation of test sets, the minimization or prioritization of test sets, and the automatic identification of identical mutants are some more focused objectives.\par 
The fault injection testing technique's most well-known criterion is mutation testing. It assesses a test case set's quality and makes improvements. So, little syntactic changes are made to the program being tested, and a changed copy of the program, known as a mutant, is produced for each change done. Modifications stand in for any errors that programmers might make while writing a program. This criterion encourages the creation of a test case collection that shows the errors introduced in mutants are not present in the original program, increasing the program's dependability \cite{ref33}. The original program uses the first set of test cases, which used to develop and run mutations. \par 
Those considered dead and no longer employed in the test behave differently from the original software. Analyzing the collection of mutants that are still alive, analogous mutants are found. It is regarded as equivalent when a mutant exhibits the same behavior as the program being tested in all test scenarios. The mutants that are still alive are finally killed in new test situations. Despite the effectiveness of mutation testing, numerous issues remain, including the vast number of mutants produced, the high computational costs associated with their execution, and the significant effort required to identify similar mutants. 
\section{Analysis of the Enhanced Mutation Testing}
In a report, Bashir assessed MuJava, a method for assessing evolutionary mutations in Java applications \cite{ref34}. Mutation testing being highly effective but very expensive needs to be made economically feasible. Therefore, by incorporating multiple approaches with different parameters and advantages, the fallacies of the testing could be eliminated. Implementation of the novel techniques such as genetic algorithm approaches can enhance the mode of testing. The primary motive of this approach is to evaluate the outcome after the implementation and consider the feasibility. \par 
Generally, mutation testing introduces the fault in the programs and generates an efficient test case to overcome the fallacies. In the paper, the author has presented the evolution mutation tools for Java for automation with a certain set of parameters to adhere to. This approach is known as eMuJava which is implemented upon four types of methods. The proposed approach by the paper allows integrating the testing with the multiple levels of the classes. eMuJava works with the 10 operators which provide operations to each mutant with one fault. The partial operators are conventional, and the other parts are object-oriented.\par 
When compared to other testing tools like Offutt, Ma and Kwon have more operators than eMuJava. The article has taken into account four different automated test case generation methods: random testing, standard genetic algorithms, improved genetic algorithms, and genetic algorithms with improved fitness functions. Here, Random Testing generated the test case in the random occurrences where the Standard Genetic Algorithm also initially follows the Random Testing but in a later stage, it learns to overcome the fallacies with the help of the previous iterations whereas the third algorithm is the addition of the fitness function to the standard function. The fourth algorithm is the enhanced counterpart of the third algorithm with the addition of a novel approach to the crossover method.\par 
In addition to this, eMuJava supports various configurative options for feasibility and convenience to perform the testing. There are six configurations, which are mostly utilized. Moreover, eMuJava is a GUI-based tool which is also one of the advantages. The author of this paper has made this program open source by making the source available to all. However, this software has a complicated internal architecture made up of three programs: a test case generator, a code instrumentation program that uses the compiler, and a mutant generator. The author depicts an elaborative graphical representation of the architecture of the program \cite{ref35}. \par 
The eMuJava does certain descriptive processes such as mutant generation, population generation, fitness evaluation, crossover, biological mutation, etc. For the statistical analysis, the paper here implemented the normality test. In the bottom line, this approach was proposed to counter the computational cost and provide convenience to the testers. For the future scope of work, the paper proposed includes more types of evolutionary techniques such as artificial immune systems, particle swarm optimization, and more.\par 
With the increasing, line of codes in large software programs, the complexity of mutation testing is hereby increased proportionally. With the surging computational time, the computational cost of the testing also increases. Therefore, it is generally seen that most entities eliminate the phase of testing in the development protocol. Mutation testing has been an efficacious method to test the given program, although it brings some alterations to the final source which can be very tedious for large software. Therefore, through this paper, the author aimed to reduce the financial burden and study the influence on the source code by the custom mutation operators.\par 
Considering the two goals, the paper is divided into two sub-parts with a detailed discussion on each. The author of the paper considered Maven as the mutation system integration tool, where the procedure is initially implemented and further studied. The Maven project created generally relied on the Project Object Model (POM) modules. Certain built-in lifecycles are default, clean, and site. In addition to this, there is various other built-in function such as validate, compile, test, package, verify, install, package, etc.\par 
To implement and authorize vendor-independent source control management (SCM) operations, there are a set of tools which is known as Maven SCM. Furthermore, for the framework, the paper considered the utilization of the Java Collections Framework (JCF). In addition, because of its increased efficacy, the installation of mutation testing in the PiTest extension is also taken into consideration. To pace the efficacy of the mutation testing, here the concept of incremental analysis has been implemented. In addition to this, the concept of differential analysis is also evaluated in the paper. \par 
To have a wider overview, the author considered multiple machines for the evaluations. With the primary motive, the author evaluated multiple strategies for cost reduction. These strategies as discussed were incremental analysis, differential analysis, and operations operators. The first method utilizes the caching mechanism to iterate the consecutive mutation tests although when compared with the differential analysis, this method could conveniently shift between multiple program versions without hindering the iterations. Furthermore, the novel operators on mutations had been able to enhance the mutation score of the testing.\par 
In one paper, \cite{ref36} proposed a method to reduce mutation testing in the java classes. The goal of the paper was to shorten the computing time without compromising the final product by lowering the number of mutations in the program. Furthermore, the paper considered selective reduction. The mutation of the model was considered using the model transformation method. In the later stage, the final mutation is converted to the text form. \par 
Fang suggested utilizing concolic and mutation testing for automated JUnit production and quality evaluation \cite{ref37}. The general motive of this concept of concurrent provides the simultaneous computational capacity of multiple programs. The proposed mutation tools in the paper are evaluated and experimented with in two systems which are the Banking system and the Incremental system. To create a fault-free program, the exceptional handling capacity of the software must be highly efficacious and reliable. The paper evaluated and tried the multiple instances to check the reliability of the proposed model.
\section{A research on students' quality-mindedness}
Researchers \cite{ref38} evaluated the quality characteristics of feedback systems, focusing on readability, convention adherence, documentation, and adequate testing. Early programming courses at colleges sometimes fail to address software quality since they concentrate on fundamental topics and frequently only employ brief exercises. Students may not understand the importance of creating high-quality code due to the tiny quantity of the required code and the fact that it is typically not improved upon after submission. In the second research, a survey was created to allow students in upper semesters to rank the significance of several quality factors. This was also utilized to learn more about their programming experience prior to attending university.\par 
Their findings were divided into a number of categories. The key finding was that success in an early programming course is strongly positively correlated with having a solid understanding of software quality. The study also found that even when they work in teams, students already place a high value on software quality. However, there is definitely room for improvement in quality awareness. Additionally, research has indicated that university classes are where the majority of students receive their first formal training in programming.
\subsection{Diagnostic Evaluation}
The authors were interested in how early learners' ultimate grades may be affected by their knowledge of software quality \cite{ref38}. A problematic tree-based Perrinsequence implementation that is comparable to the student’s prior knowledge of the Fibonacci sequence was given to them for their first exam. Citizens who encountered issues with the Perrin sequence implementation were enrolled for the repeat test. The first exam attracted around 130 candidates, while the second exam attracted roughly 60 students. The other students chose to immediately participate in the repeat exam because 60 of them had previously taken the first exam and failed it. An outcome is a number between -1 and +1, with +1 being the strongest association and 0 denoting no correlation at all. This implies that the highest scores would go to students who had no notion of quality while the lowest scores would go to students who had the notion of quality.\par 
The first exam's results were calculated using correlations, and the final scores were 0.55 (writing tests), 0.41 (spotting/fixing a fault), and 0.61 (entire work) while any number greater than 0.4 was regarded as a favorable connection. The item-test correlation for authoring the tests may still be determined to be 0.34 with a lower sample size of just roughly 60 learners. The majority of test-takers who took the exam again neglected to include the component that contains, resulting in an item-test connection of 0.01 and a task connection of 0.25. The first exam's strong correlation shows that future investigation into the relationship between quality-mindedness and causality is worthwhile.
\subsection{Survey Questions for Students}
The participants in a course that was offered between the second and third semesters were also surveyed for the study. The survey's goal was to find out how much thought students put to software quality while working in groups or alone. Going into every measure would have revealed the survey and possibly discouraged students from taking part.  The researchers, therefore, included 9 measures in their poll to avoid this.\par 
\cite{ref38} Chose the least common denominator of the courses that students were supposed to finish. The idea of Magic Numbers and the "Don't Repeat Yourself" maxim, which seem to be crucial to understanding the metric Duplicated Code, was required of the pupils. The metrics' names were taken into account as the second selection criterion. Students would be able to get some idea of what they were about from those with names that were self-explanatory. Another aspect to take into account while selecting a measure was testing. Both beginning courses and testing metrics address source code testing, which is crucial for assuring the competence of software.\par 
There is little indication that any one group of students stands out in the study, but only 40 of the 110 students were surveyed, so the findings may be affected. 15-20\% of female students specialized in computer science, which was 87\% male, just 8\% of the student population was female. 5\% of the participants completely avoided the question. Approximately 29\% of students were in their third semester, while 50\% were in their second semester. Students made up 9\% of those in their fourth and 8\% of those in their fifth semesters. In their tenth semester, only 2\% of the students were present. This supports the notion that most individuals were just commencing their undergraduate studies.\par 
Before beginning the first semester, students were asked to assess their past computer science knowledge from a wide range of possible areas. There were no students that answered no to any of these questions. Only around 50\% of students had formal computer science training prior to entering college, and the majority of their previous knowledge was acquired through private sources \cite{ref39}. Working in the sector did not provide any students with prior expertise. Therefore, the university provided the first formal education that the other half of the students received.\par 
Many CS students find it difficult to develop the understanding and analysis abilities that are essential for software development, according to Edwards \cite{ref40}. In order to overcome this, they advise making junior-level school curriculum exams and establishing an automated testing instrument that will give students feedback fewer defects in the students’ code according to research \cite{ref41} comparing courses 45\% with and without TDD.\par 
Prof. CI is a revolutionary way of programming exercises and instructing test-driven development that Matthies et al. \cite{ref42} suggest. It makes use of modern, IDE-based training tools and modern, online courses designed expressly for learning how to code. The research found that the students were more motivated to develop more tests in subsequent tasks. By changing the curriculum of the introductory courses at our university, we want to educate junior-level students with improved code quality standards. This modification will be done largely by redesigning the assignments that must be completed during the semester and by using an IDE- and web-based tool to provide quality feedback.
\section{Feedback systems using mutation testing}
Feedback systems using mutation testing have become an important tool in software engineering. Software testing methods known as "mutation testing" include making minor "mutations" to existing code in order to evaluate the system's resilience. A feedback mechanism is employed to assess the efficiency of the mutation testing procedure and inform developers of the parts of the code that still require development \cite{ref43}.\par 
One example of a feedback system used for mutation testing is the Mutational Divergence Score (MDS) \cite{ref44}. The MDS measures the degree of divergence between two versions of a program using a combination of both static and dynamic approaches. The MDS has been found to be effective in giving developers an indication of how well their mutation tests are working in comparison with previous versions, allowing them to focus their efforts on areas where improvement can be made.\par 
Another feedback system proposed for use with mutation testing is the Fault-Resistant Test Generation Tool (FRTG) \cite{ref45}. FRTG provides feedback regarding test coverage, fault detection, and mutation scores for each test case. In addition, FRTG also provides metrics such as mutation score distribution, fault intensity, and fault propagation rate which can help developers identify areas within their code where mutations are more likely to occur and require additional testing efforts. FRTG has been proven to be effective in providing detailed insights into how well mutation tests are performing, enabling developers to make informed decisions on where they need to focus their efforts when improving existing tests or developing new ones.\par 
PiTest was created to offer thorough feedback on test results by adding minor "mutations" to a program's source code \cite{ref46}. When using PiTest, developers specify which parts of their source code they want to mutate, as well as criteria for detecting errors in test results (e.g., timing differences). After generating mutations based on these specifications, PiTest runs individual tests (or sets of tests) against each mutated version and compares their expected output with actual output; any discrepancies are flagged as errors and reported back to developers with detailed information about where in their code those errors occurred. In addition to providing this feedback quickly during development cycles, it also helps developers identify parts of their code that need further testing before release. Several studies have used PiTest to evaluate existing software tests and provide feedback on which parts of their code require additional testing effort. For example, according to research by Fujii et al., utilizing PiTest and mutation analysis to find problems in Java applications that aren't caught by current unit tests is beneficial; it identified 20\% more bugs than manual inspection alone did.\par 
Another feedback system that has been proposed for use with mutation testing is the Adaptive Automated Reasoning System (AARS) \cite{ref47}. In order to identify possible flaws in the program being tested, AARS analyses data from an existing test suite using machine learning methods. Based on its analysis, AARS then offers feedback on which areas of the code are more prone to mistakes and recommends relevant actions that should be performed to enhance the calibre of tests being developed for this specific piece of code. AARS has been found to be effective in helping developers identify areas within their code where additional attention needs to be paid when creating tests and can significantly improve their overall efficiency when writing new tests or debugging existing ones.\par 
According to a structure of research, giving students individualized and automated feedback during programming projects may be able to help them develop their coding abilities and comprehend subjects more fully. Furthermore, existing tools such as PiTest and Unit Test Generator can be used for quickly generating test cases from mutations or unit tests from mutants, respectively, which allows programmers to generate customized feedback without having to manually create test cases or unit tests from scratch. Additionally, my proposed system for generating automated feedback based on mutation testing has been tested and found to provide greater insight into a student's code than traditional approaches such as static analysis or manual inspection. Taking all these findings into account, it is clear that utilizing customized feedback systems during programming assignments can help instructors provide more effective guidance while still saving time.
\section{A Research on the Impact of Feedback to Programming Students} 
Formative feedback has been shown to be an effective method that is useful for programming student learning and vital to enhancing knowledge and skill acquisition. Offering students with constructive feedback has been shown to be effective \cite{ref48} Throughout the learning process and in the context of certain learning activities, formative feedback might flag a gap between a learner's present level of performance and some intended level of performance \cite{ref49}. It is anticipated that the greatest influence on students' comprehension would result from encouraging them to reflect on their work while they are actively interacting with the topic and activity \cite{ref50}. Finding a solution to the problem might also encourage higher degrees of educational endeavors \cite{ref51}. Students are able to evaluate which areas of knowledge they need to investigate in greater depth and which aspects of their thinking need to be modified with the assistance of this vital information. In addition, learners, particularly novices, students who are having difficulty and students who are performing poorly, can have their cognitive load efficiently reduced by using formative feedback \cite{ref52}. According to the findings of previous research \cite{ref53}, it appears that students are in particular need of guidance when they become stuck.\par 
A substantial influence has been exerted on educational evaluation by the profusion of computer-related technologies that are readily available to the public. According to \cite{ref54}, there has been an increase in the usage of technology to facilitate the delivery or submission of assignments as well as the medium for providing feedback. For instance, the implementation of learning management systems (LMSs) or course management systems (CMSs) can alleviate the high workload associated with the submission and grading of assignments (e.g., Moodle, Blackboard, WebCT, Canvas) as well as the detection of plagiarism (e.g., Turnitin) \cite{ref55}, among other issues. After students submit their assignments or responses, teachers can manually analyze the student's writings or responses using these systems, evaluate how well the students did on their assignments, and provide feedback or comments to the students online.\par 
Techniques from the fields of data mining and natural language processing (NLP) are increasingly being utilized in the field of education, particularly in the area of automatic educational assessment, as a result of the proliferation of computer-based educational technologies. Implementing computer-based feedback could be an alternative to the traditional method of receiving comments from teachers \cite{ref56}. A variation of computer-based frameworks or tools has been designed to automate the process of scoring and providing feedback to cater to the requirements of a variety of different writing contexts. These systems and tools have been developed by drawing on the multidisciplinary insights found in linguistics, computer science, and educational data mining. According to what is suggested in \cite{ref57}, both scores and feedback in these systems are typically based on the linguistic characteristics of the student discourse. These linguistic characteristics include, but are not limited to lower-level mistakes in response (such as spelling or grammatical errors in written responses); discourse organization and structure of a piece of writing; and relevance of the discourse to the question that was asked.\par  
Many different kinds of automatic programming feedback have been developed by researchers and programming practitioners. Compilers provide the most fundamental kind of syntactic feedback known as error messages, which have the potential to be significantly improved by adding text that is both clearer and more specific \cite{ref58, ref59}. In addition, the majority of environments for practicing programming, such as CodeWorkout \cite{ref60} and Cloudcoder \cite{ref61}, provide students with the opportunity to receive feedback by running their own code through a series of test cases, each of which can either succeed or fail. Other auto graders, such as \cite{ref62, ref63}, provide feedback in block-based languages by employing static analysis. Block-based languages do not make use of compilers.

\section{Conclusion} 

This literature review has explored several models and automatic feedback mechanisms related to developing an automatic feedback system capable of generating high-quality code by utilizing metrics and mutation testing techniques. I have seen how important it is when creating such a system, to consider readability, documentation, and sufficient testing since these are crucial elements that need consideration. I have also studied how giving timely personalized hints helps students become more self-directed learners and the impact of providing incentives on student performance. \par 
In conclusion, by exploring the various research studies related to feedback systems, automated testing tools, mutation testing tools, and other technologies used for generating test cases from mutations and unit tests from mutants. I have identified potential gaps that exist in the application and implementation of feedback systems for early learners of object-oriented programming with basic knowledge of JUnit Testing. Additionally, I have explored how mutation testing can be used to generate automated feedback hints to the students.





